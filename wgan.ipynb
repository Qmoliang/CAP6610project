{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-6d7a75843687>:14: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../../MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Iter-0; D_loss: -0.15103307366371155; G_loss: 0.18560005724430084\n",
      "Iter-2000; D_loss: -0.007170230150222778; G_loss: 0.0647735446691513\n",
      "Iter-4000; D_loss: -0.0569344162940979; G_loss: -0.026285730302333832\n",
      "Iter-6000; D_loss: -0.03135409206151962; G_loss: -0.028608782216906548\n",
      "Iter-8000; D_loss: -0.032348114997148514; G_loss: -0.02514425292611122\n",
      "Iter-10000; D_loss: -0.029389889910817146; G_loss: -0.01955932006239891\n",
      "Iter-12000; D_loss: -0.02400495857000351; G_loss: -0.022684214636683464\n",
      "Iter-14000; D_loss: -0.020620692521333694; G_loss: -0.024134265258908272\n",
      "Iter-16000; D_loss: -0.018149128183722496; G_loss: -0.024032115936279297\n",
      "Iter-18000; D_loss: -0.01392601989209652; G_loss: -0.023193102329969406\n",
      "Iter-20000; D_loss: -0.015843404456973076; G_loss: -0.022170839831233025\n",
      "Iter-22000; D_loss: -0.015283502638339996; G_loss: -0.02461335062980652\n",
      "Iter-24000; D_loss: -0.010483378544449806; G_loss: -0.02384389005601406\n",
      "Iter-26000; D_loss: -0.013457342982292175; G_loss: -0.023036645725369453\n",
      "Iter-28000; D_loss: -0.01020057313144207; G_loss: -0.024725694209337234\n",
      "Iter-30000; D_loss: -0.01166551187634468; G_loss: -0.023245539516210556\n",
      "Iter-32000; D_loss: -0.009984908625483513; G_loss: -0.024776367470622063\n",
      "Iter-34000; D_loss: -0.01151004433631897; G_loss: -0.024937724694609642\n",
      "Iter-36000; D_loss: -0.01087275892496109; G_loss: -0.02595660462975502\n",
      "Iter-38000; D_loss: -0.009721506386995316; G_loss: -0.024411439895629883\n",
      "Iter-40000; D_loss: -0.011653739959001541; G_loss: -0.02244694158434868\n",
      "Iter-42000; D_loss: -0.008105546236038208; G_loss: -0.02148411050438881\n",
      "Iter-44000; D_loss: -0.006451670080423355; G_loss: -0.02452920190989971\n",
      "Iter-46000; D_loss: -0.007411079481244087; G_loss: -0.02371019870042801\n",
      "Iter-48000; D_loss: -0.007164748385548592; G_loss: -0.024189455434679985\n",
      "Iter-50000; D_loss: -0.00760912150144577; G_loss: -0.024215906858444214\n",
      "Iter-52000; D_loss: -0.010094162076711655; G_loss: -0.024078238755464554\n",
      "Iter-54000; D_loss: -0.00943002663552761; G_loss: -0.02235877513885498\n",
      "Iter-56000; D_loss: -0.007898455485701561; G_loss: -0.02443639002740383\n",
      "Iter-58000; D_loss: -0.009128767997026443; G_loss: -0.02276637963950634\n",
      "Iter-60000; D_loss: -0.008666779845952988; G_loss: -0.022279037162661552\n",
      "Iter-62000; D_loss: -0.007328975945711136; G_loss: -0.022610772401094437\n",
      "Iter-64000; D_loss: -0.009244220331311226; G_loss: -0.022922523319721222\n",
      "Iter-66000; D_loss: -0.00774306058883667; G_loss: -0.02032395824790001\n",
      "Iter-68000; D_loss: -0.005398809909820557; G_loss: -0.02205968275666237\n",
      "Iter-70000; D_loss: -0.010038377717137337; G_loss: -0.02596442960202694\n",
      "Iter-72000; D_loss: -0.010045580565929413; G_loss: -0.019301941618323326\n",
      "Iter-74000; D_loss: -0.00661265105009079; G_loss: -0.02317778393626213\n",
      "Iter-76000; D_loss: -0.007859086617827415; G_loss: -0.02329516038298607\n",
      "Iter-78000; D_loss: -0.009627195075154305; G_loss: -0.022310858592391014\n",
      "Iter-80000; D_loss: -0.006716553121805191; G_loss: -0.01971244066953659\n",
      "Iter-82000; D_loss: -0.004933575168251991; G_loss: -0.018054433166980743\n",
      "Iter-84000; D_loss: -0.00876939482986927; G_loss: -0.01936868391931057\n",
      "Iter-86000; D_loss: -0.0077991727739572525; G_loss: -0.021907221525907516\n",
      "Iter-88000; D_loss: -0.007005816325545311; G_loss: -0.01729908213019371\n",
      "Iter-90000; D_loss: -0.004820533096790314; G_loss: -0.019161680713295937\n",
      "Iter-92000; D_loss: -0.011532295495271683; G_loss: -0.024792823940515518\n",
      "Iter-94000; D_loss: -0.00545879453420639; G_loss: -0.02161305956542492\n",
      "Iter-96000; D_loss: -0.008281663060188293; G_loss: -0.021281784400343895\n",
      "Iter-98000; D_loss: -0.009050549939274788; G_loss: -0.017031723633408546\n",
      "Iter-100000; D_loss: -0.007952721789479256; G_loss: -0.018657345324754715\n",
      "Iter-102000; D_loss: -0.009774843230843544; G_loss: -0.019298521801829338\n",
      "Iter-104000; D_loss: -0.010008055716753006; G_loss: -0.01667470484972\n",
      "Iter-106000; D_loss: -0.008602194488048553; G_loss: -0.011769217438995838\n",
      "Iter-108000; D_loss: -0.004551825113594532; G_loss: -0.013842148706316948\n",
      "Iter-110000; D_loss: -0.006769624538719654; G_loss: -0.014360212720930576\n",
      "Iter-112000; D_loss: -0.007718978449702263; G_loss: -0.019470082595944405\n",
      "Iter-114000; D_loss: -0.007780326530337334; G_loss: -0.01546136848628521\n",
      "Iter-116000; D_loss: -0.009223079308867455; G_loss: -0.01967247761785984\n",
      "Iter-118000; D_loss: -0.007124461233615875; G_loss: -0.016118036583065987\n",
      "Iter-120000; D_loss: -0.009238386526703835; G_loss: -0.01277145929634571\n",
      "Iter-122000; D_loss: -0.00949341431260109; G_loss: -0.019908271729946136\n",
      "Iter-124000; D_loss: -0.01192164421081543; G_loss: -0.018297117203474045\n",
      "Iter-126000; D_loss: -0.004139954224228859; G_loss: -0.017363740131258965\n",
      "Iter-128000; D_loss: -0.00763360969722271; G_loss: -0.016766555607318878\n",
      "Iter-130000; D_loss: -0.00612195860594511; G_loss: -0.013334895484149456\n",
      "Iter-132000; D_loss: -0.00585915707051754; G_loss: -0.01674070581793785\n",
      "Iter-134000; D_loss: -0.008964154869318008; G_loss: -0.020332016050815582\n",
      "Iter-136000; D_loss: -0.005748113617300987; G_loss: -0.017612451687455177\n",
      "Iter-138000; D_loss: -0.005686648190021515; G_loss: -0.02020912989974022\n",
      "Iter-140000; D_loss: -0.006790252402424812; G_loss: -0.014758714474737644\n",
      "Iter-142000; D_loss: -0.009299864992499352; G_loss: -0.017346851527690887\n",
      "Iter-144000; D_loss: -0.007313171401619911; G_loss: -0.02120436728000641\n",
      "Iter-146000; D_loss: -0.007561003789305687; G_loss: -0.015242230147123337\n",
      "Iter-148000; D_loss: -0.012128723785281181; G_loss: -0.017968788743019104\n",
      "Iter-150000; D_loss: -0.005211048759520054; G_loss: -0.012286335229873657\n",
      "Iter-152000; D_loss: -0.006493802182376385; G_loss: -0.01477095391601324\n",
      "Iter-154000; D_loss: -0.007349923253059387; G_loss: -0.017083359882235527\n",
      "Iter-156000; D_loss: -0.008532813750207424; G_loss: -0.018214600160717964\n",
      "Iter-158000; D_loss: -0.007815966382622719; G_loss: -0.020061660557985306\n",
      "Iter-160000; D_loss: -0.006340428255498409; G_loss: -0.013174016959965229\n",
      "Iter-162000; D_loss: -0.006849335506558418; G_loss: -0.01864859089255333\n",
      "Iter-164000; D_loss: -0.004453149624168873; G_loss: -0.014606354758143425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-166000; D_loss: -0.007062479853630066; G_loss: -0.011770438402891159\n",
      "Iter-168000; D_loss: -0.008834542706608772; G_loss: -0.021600160747766495\n",
      "Iter-170000; D_loss: -0.0069620730355381966; G_loss: -0.009766893461346626\n",
      "Iter-172000; D_loss: -0.005577122792601585; G_loss: -0.014154132455587387\n",
      "Iter-174000; D_loss: -0.008548211306333542; G_loss: -0.02115953341126442\n",
      "Iter-176000; D_loss: -0.00440484844148159; G_loss: -0.014142677187919617\n",
      "Iter-178000; D_loss: -0.008657854050397873; G_loss: -0.016980934888124466\n",
      "Iter-180000; D_loss: -0.006986429914832115; G_loss: -0.01571401208639145\n",
      "Iter-182000; D_loss: -0.005954526364803314; G_loss: -0.014795857481658459\n",
      "Iter-184000; D_loss: -0.007927127182483673; G_loss: -0.020439980551600456\n",
      "Iter-186000; D_loss: -0.006919161416590214; G_loss: -0.01105736568570137\n",
      "Iter-188000; D_loss: -0.00699373334646225; G_loss: -0.01377302035689354\n",
      "Iter-190000; D_loss: -0.006946500390768051; G_loss: -0.011396193876862526\n",
      "Iter-192000; D_loss: -0.005829913541674614; G_loss: -0.0220482274889946\n",
      "Iter-194000; D_loss: -0.006603398360311985; G_loss: -0.00737847201526165\n",
      "Iter-196000; D_loss: -0.007173839956521988; G_loss: -0.015342668630182743\n",
      "Iter-198000; D_loss: -0.004157383926212788; G_loss: -0.011772477999329567\n",
      "Iter-200000; D_loss: -0.0019357521086931229; G_loss: -0.020161017775535583\n",
      "Iter-202000; D_loss: -0.005782010033726692; G_loss: -0.018425241112709045\n",
      "Iter-204000; D_loss: -0.008325261995196342; G_loss: -0.015372592024505138\n",
      "Iter-206000; D_loss: -0.0038829874247312546; G_loss: -0.011315540410578251\n",
      "Iter-208000; D_loss: -0.007746422663331032; G_loss: -0.010508943349123001\n",
      "Iter-210000; D_loss: -0.005490373820066452; G_loss: -0.015299343504011631\n",
      "Iter-212000; D_loss: -0.0062325093895196915; G_loss: -0.014033476822078228\n",
      "Iter-214000; D_loss: -0.005097114481031895; G_loss: -0.01886717416346073\n",
      "Iter-216000; D_loss: -0.00412297248840332; G_loss: -0.011069327592849731\n",
      "Iter-218000; D_loss: -0.005945044569671154; G_loss: -0.011126460507512093\n",
      "Iter-220000; D_loss: -0.006088906899094582; G_loss: -0.008631951175630093\n",
      "Iter-222000; D_loss: -0.006897611543536186; G_loss: -0.014955856837332249\n",
      "Iter-224000; D_loss: -0.0043056420981884; G_loss: -0.014020955190062523\n",
      "Iter-226000; D_loss: -0.009897066280245781; G_loss: -0.012456299737095833\n",
      "Iter-228000; D_loss: -0.007606791332364082; G_loss: -0.014183355495333672\n",
      "Iter-230000; D_loss: -0.005546869710087776; G_loss: -0.018024828284978867\n",
      "Iter-232000; D_loss: -0.0038911281153559685; G_loss: -0.010755270719528198\n",
      "Iter-234000; D_loss: -0.004107430577278137; G_loss: -0.013646319508552551\n",
      "Iter-236000; D_loss: -0.006699768826365471; G_loss: -0.013414806686341763\n",
      "Iter-238000; D_loss: -0.009682324714958668; G_loss: -0.01424197293817997\n",
      "Iter-240000; D_loss: -0.008931448683142662; G_loss: -0.018100544810295105\n",
      "Iter-242000; D_loss: -0.00887848436832428; G_loss: -0.016456985846161842\n",
      "Iter-244000; D_loss: -0.0018966495990753174; G_loss: -0.019804833456873894\n",
      "Iter-246000; D_loss: -0.004461178556084633; G_loss: -0.010100561194121838\n",
      "Iter-248000; D_loss: -0.004943329840898514; G_loss: -0.010090799070894718\n",
      "Iter-250000; D_loss: -0.008113427087664604; G_loss: -0.00881417840719223\n",
      "Iter-252000; D_loss: -0.00857927743345499; G_loss: -0.012445364147424698\n",
      "Iter-254000; D_loss: -0.005410199984908104; G_loss: -0.010058805346488953\n",
      "Iter-256000; D_loss: -0.006652700714766979; G_loss: -0.011318419128656387\n",
      "Iter-258000; D_loss: -0.0033212611451745033; G_loss: -0.007239422295242548\n",
      "Iter-260000; D_loss: -0.007105331867933273; G_loss: -0.01859666220843792\n",
      "Iter-262000; D_loss: -0.007681285031139851; G_loss: -0.01526562124490738\n",
      "Iter-264000; D_loss: -0.0073617007583379745; G_loss: -0.017298880964517593\n",
      "Iter-266000; D_loss: -0.004692052491009235; G_loss: -0.011423769406974316\n",
      "Iter-268000; D_loss: -0.00484887883067131; G_loss: -0.016454976052045822\n",
      "Iter-270000; D_loss: -0.003959571942687035; G_loss: -0.011137302964925766\n",
      "Iter-272000; D_loss: -0.008459670469164848; G_loss: -0.010785076767206192\n",
      "Iter-274000; D_loss: -0.006493451073765755; G_loss: -0.013966955244541168\n",
      "Iter-276000; D_loss: -0.009626067243516445; G_loss: -0.012363506481051445\n",
      "Iter-278000; D_loss: -0.004086621105670929; G_loss: -0.013185239396989346\n",
      "Iter-280000; D_loss: -0.008580420166254044; G_loss: -0.02638263814151287\n",
      "Iter-282000; D_loss: -0.007386478595435619; G_loss: -0.014406517148017883\n",
      "Iter-284000; D_loss: -0.00848770048469305; G_loss: -0.012242868542671204\n",
      "Iter-286000; D_loss: -0.0054345326498150826; G_loss: -0.013359191827476025\n",
      "Iter-288000; D_loss: -0.004866407252848148; G_loss: -0.014326905831694603\n",
      "Iter-290000; D_loss: -0.01221742108464241; G_loss: -0.015785930678248405\n",
      "Iter-292000; D_loss: -0.0064554521813988686; G_loss: -0.013455964624881744\n",
      "Iter-294000; D_loss: -0.007545739412307739; G_loss: -0.019864816218614578\n",
      "Iter-296000; D_loss: -0.00369306281208992; G_loss: -0.010346568189561367\n",
      "Iter-298000; D_loss: -0.010129868984222412; G_loss: -0.008400902152061462\n",
      "Iter-300000; D_loss: -0.004257486201822758; G_loss: -0.005960824899375439\n",
      "Iter-302000; D_loss: -0.006599015556275845; G_loss: -0.012672143056988716\n",
      "Iter-304000; D_loss: -0.0052788276225328445; G_loss: -0.015080122277140617\n",
      "Iter-306000; D_loss: -0.004752038978040218; G_loss: -0.010161842219531536\n",
      "Iter-308000; D_loss: -0.005381997674703598; G_loss: -0.01976020447909832\n",
      "Iter-310000; D_loss: -0.008290574885904789; G_loss: -0.014478707686066628\n",
      "Iter-312000; D_loss: -0.003340119495987892; G_loss: -0.015141984447836876\n",
      "Iter-314000; D_loss: -0.007056115195155144; G_loss: -0.017466260120272636\n",
      "Iter-316000; D_loss: -0.006230744533240795; G_loss: -0.01461130939424038\n",
      "Iter-318000; D_loss: -0.00841708853840828; G_loss: -0.02015043795108795\n",
      "Iter-320000; D_loss: -0.009276196360588074; G_loss: -0.016116468235850334\n",
      "Iter-322000; D_loss: -0.006565202958881855; G_loss: -0.01709543727338314\n",
      "Iter-324000; D_loss: -0.0046684714034199715; G_loss: -0.006319588050246239\n",
      "Iter-326000; D_loss: -0.007923224940896034; G_loss: -0.017073839902877808\n",
      "Iter-328000; D_loss: -0.011721199378371239; G_loss: -0.017430435866117477\n",
      "Iter-330000; D_loss: -0.007798755541443825; G_loss: -0.015371283516287804\n",
      "Iter-332000; D_loss: -0.007752042263746262; G_loss: -0.014746171422302723\n",
      "Iter-334000; D_loss: -0.0012411829084157944; G_loss: -0.011234957724809647\n",
      "Iter-336000; D_loss: -0.006045876070857048; G_loss: -0.013297852128744125\n",
      "Iter-338000; D_loss: -0.0054782601073384285; G_loss: -0.016934286803007126\n",
      "Iter-340000; D_loss: -0.006922880187630653; G_loss: -0.015266342088580132\n",
      "Iter-342000; D_loss: -0.0042696744203567505; G_loss: -0.01246106531471014\n",
      "Iter-344000; D_loss: -0.0045663779601454735; G_loss: -0.013257159851491451\n",
      "Iter-346000; D_loss: -0.011014921590685844; G_loss: -0.016011614352464676\n",
      "Iter-348000; D_loss: -0.004893388599157333; G_loss: -0.01497200783342123\n",
      "Iter-350000; D_loss: -0.0031298110261559486; G_loss: -0.004825381562113762\n",
      "Iter-352000; D_loss: -0.006371377035975456; G_loss: -0.01750977151095867\n",
      "Iter-354000; D_loss: -0.0057532936334609985; G_loss: -0.0126727893948555\n",
      "Iter-356000; D_loss: -0.00780697725713253; G_loss: -0.01812729611992836\n",
      "Iter-358000; D_loss: -0.003604726865887642; G_loss: -0.014663510024547577\n",
      "Iter-360000; D_loss: -0.008247818797826767; G_loss: -0.011972376145422459\n",
      "Iter-362000; D_loss: -0.001760031096637249; G_loss: -0.009463991969823837\n",
      "Iter-364000; D_loss: -0.0029670847579836845; G_loss: -0.01290166936814785\n",
      "Iter-366000; D_loss: -0.007082978263497353; G_loss: -0.019107438623905182\n",
      "Iter-368000; D_loss: -0.005608260631561279; G_loss: -0.022937467321753502\n",
      "Iter-370000; D_loss: -0.0037484485656023026; G_loss: -0.01392623595893383\n",
      "Iter-372000; D_loss: -0.0046105701476335526; G_loss: -0.015904145315289497\n",
      "Iter-374000; D_loss: -0.005014095455408096; G_loss: -0.013323417864739895\n",
      "Iter-376000; D_loss: -0.0018751844763755798; G_loss: -0.009202320128679276\n",
      "Iter-378000; D_loss: -0.00473465770483017; G_loss: -0.01926836557686329\n",
      "Iter-380000; D_loss: -0.0071127749979496; G_loss: -0.018139904364943504\n",
      "Iter-382000; D_loss: -0.007535136304795742; G_loss: -0.009225239977240562\n",
      "Iter-384000; D_loss: -0.007799776270985603; G_loss: -0.008653031662106514\n",
      "Iter-386000; D_loss: -0.00594061566516757; G_loss: -0.0070326970890164375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-388000; D_loss: -0.004220424219965935; G_loss: -0.011734329164028168\n",
      "Iter-390000; D_loss: -0.005558038130402565; G_loss: -0.011463439092040062\n",
      "Iter-392000; D_loss: -0.0051558250561356544; G_loss: -0.01378764770925045\n",
      "Iter-394000; D_loss: -0.0030943695455789566; G_loss: -0.009213672019541264\n",
      "Iter-396000; D_loss: -0.002217203378677368; G_loss: -0.021612118929624557\n",
      "Iter-398000; D_loss: -0.008502266369760036; G_loss: -0.015876300632953644\n",
      "Iter-400000; D_loss: -0.004081017337739468; G_loss: -0.014284889213740826\n",
      "Iter-402000; D_loss: -0.003024960868060589; G_loss: -0.012510934844613075\n",
      "Iter-404000; D_loss: -0.0020343028008937836; G_loss: -0.008617954328656197\n",
      "Iter-406000; D_loss: -0.0021936800330877304; G_loss: -0.01839528977870941\n",
      "Iter-408000; D_loss: -0.0031514307484030724; G_loss: -0.010939806699752808\n",
      "Iter-410000; D_loss: -0.0061295367777347565; G_loss: -0.018334753811359406\n",
      "Iter-412000; D_loss: -0.0073374006897211075; G_loss: -0.009762465953826904\n",
      "Iter-414000; D_loss: -0.005367908626794815; G_loss: -0.016656354069709778\n",
      "Iter-416000; D_loss: -0.006316883489489555; G_loss: -0.011797401122748852\n",
      "Iter-418000; D_loss: -0.005990419536828995; G_loss: -0.020192362368106842\n",
      "Iter-420000; D_loss: -0.003279566764831543; G_loss: -0.017707444727420807\n",
      "Iter-422000; D_loss: -0.007780873216688633; G_loss: -0.013376831077039242\n",
      "Iter-424000; D_loss: -0.007521977648139; G_loss: -0.012698957696557045\n",
      "Iter-426000; D_loss: -0.0008508563041687012; G_loss: -0.016562145203351974\n",
      "Iter-428000; D_loss: -0.005566321313381195; G_loss: -0.01850453019142151\n",
      "Iter-430000; D_loss: -0.005873320624232292; G_loss: -0.013117905706167221\n",
      "Iter-432000; D_loss: -0.006207948550581932; G_loss: -0.011204928159713745\n",
      "Iter-434000; D_loss: -0.006834919564425945; G_loss: -0.00566949974745512\n",
      "Iter-436000; D_loss: -0.009909555315971375; G_loss: -0.011460435576736927\n",
      "Iter-438000; D_loss: -0.003372013568878174; G_loss: -0.01877181977033615\n",
      "Iter-440000; D_loss: -0.006584645248949528; G_loss: -0.013266140595078468\n",
      "Iter-442000; D_loss: -0.008568866178393364; G_loss: -0.01287154108285904\n",
      "Iter-444000; D_loss: -0.004589729011058807; G_loss: -0.013815511018037796\n",
      "Iter-446000; D_loss: -0.0037700943648815155; G_loss: -0.011874779127538204\n",
      "Iter-448000; D_loss: -0.005077717825770378; G_loss: -0.013791598379611969\n",
      "Iter-450000; D_loss: -0.005693655461072922; G_loss: -0.008658603765070438\n",
      "Iter-452000; D_loss: -0.0022100377827882767; G_loss: -0.016244111582636833\n",
      "Iter-454000; D_loss: -0.006277324631810188; G_loss: -0.01518808864057064\n",
      "Iter-456000; D_loss: -0.002027023583650589; G_loss: -0.018724165856838226\n",
      "Iter-458000; D_loss: -0.007392816245555878; G_loss: -0.018015312030911446\n",
      "Iter-460000; D_loss: -0.005249490961432457; G_loss: -0.011651342734694481\n",
      "Iter-462000; D_loss: -0.005675067193806171; G_loss: -0.011930993758141994\n",
      "Iter-464000; D_loss: -0.0045585036277771; G_loss: -0.008404440246522427\n",
      "Iter-466000; D_loss: -0.0038526626303792; G_loss: -0.008195995353162289\n",
      "Iter-468000; D_loss: -0.005687235854566097; G_loss: -0.012864897958934307\n",
      "Iter-470000; D_loss: -0.004247846081852913; G_loss: -0.011654216796159744\n",
      "Iter-472000; D_loss: -0.008375374600291252; G_loss: -0.013817409984767437\n",
      "Iter-474000; D_loss: -0.0037297168746590614; G_loss: -0.012176241725683212\n",
      "Iter-476000; D_loss: -0.004916096106171608; G_loss: -0.008338617160916328\n",
      "Iter-478000; D_loss: -0.0034781377762556076; G_loss: -0.008372874930500984\n",
      "Iter-480000; D_loss: -0.003227643668651581; G_loss: -0.01252979226410389\n",
      "Iter-482000; D_loss: -0.003534697461873293; G_loss: -0.003247440792620182\n",
      "Iter-484000; D_loss: -0.0016506966203451157; G_loss: -0.009825319051742554\n",
      "Iter-486000; D_loss: -0.005420857109129429; G_loss: -0.01504515577107668\n",
      "Iter-488000; D_loss: -0.0017564678564667702; G_loss: -0.011308325454592705\n",
      "Iter-490000; D_loss: -0.004313711076974869; G_loss: -0.009063887409865856\n",
      "Iter-492000; D_loss: -0.0018875449895858765; G_loss: -0.015283798798918724\n",
      "Iter-494000; D_loss: -0.005250114947557449; G_loss: -0.02322172373533249\n",
      "Iter-496000; D_loss: -0.0049644578248262405; G_loss: -0.019088149070739746\n",
      "Iter-498000; D_loss: -0.00475205946713686; G_loss: -0.011625447310507298\n",
      "Iter-500000; D_loss: -0.0037604570388793945; G_loss: -0.01376166008412838\n",
      "Iter-502000; D_loss: -0.0051835328340530396; G_loss: -0.020086068660020828\n",
      "Iter-504000; D_loss: -0.005085619166493416; G_loss: -0.009655981324613094\n",
      "Iter-506000; D_loss: -0.003680650144815445; G_loss: -0.012610368430614471\n",
      "Iter-508000; D_loss: -0.004174167290329933; G_loss: -0.007974537089467049\n",
      "Iter-510000; D_loss: -0.005538693629205227; G_loss: -0.010265409015119076\n",
      "Iter-512000; D_loss: -0.0067804669961333275; G_loss: -0.00647132471203804\n",
      "Iter-514000; D_loss: -0.0022118501365184784; G_loss: -0.019324105232954025\n",
      "Iter-516000; D_loss: -0.003311876207590103; G_loss: -0.013306600041687489\n",
      "Iter-518000; D_loss: -0.0031844163313508034; G_loss: -0.01467356737703085\n",
      "Iter-520000; D_loss: -0.00777031434699893; G_loss: -0.01099576149135828\n",
      "Iter-522000; D_loss: -0.00819071289151907; G_loss: -0.014286312274634838\n",
      "Iter-524000; D_loss: -0.008019721135497093; G_loss: -0.007285141386091709\n",
      "Iter-526000; D_loss: -0.00759940966963768; G_loss: -0.020483069121837616\n",
      "Iter-528000; D_loss: -0.004899613559246063; G_loss: -0.00990954041481018\n",
      "Iter-530000; D_loss: -0.004204095341265202; G_loss: -0.008441356010735035\n",
      "Iter-532000; D_loss: -0.0012644976377487183; G_loss: -0.01794746331870556\n",
      "Iter-534000; D_loss: -0.006000676192343235; G_loss: -0.011662748642265797\n",
      "Iter-536000; D_loss: -0.004898347891867161; G_loss: -0.007130573503673077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6d7a75843687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Dicriminator forward-loss-backward-update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mG_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mD_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mD_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "mb_size = 32\n",
    "z_dim = 10\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "G = torch.nn.Sequential(\n",
    "    torch.nn.Linear(z_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, X_dim),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "D = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, 1),\n",
    ")\n",
    "\n",
    "\n",
    "def reset_grad():\n",
    "    G.zero_grad()\n",
    "    D.zero_grad()\n",
    "\n",
    "\n",
    "G_solver = optim.RMSprop(G.parameters(), lr=lr)\n",
    "D_solver = optim.RMSprop(D.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for it in range(1000000):\n",
    "    for _ in range(5):\n",
    "        # Sample data\n",
    "        z = Variable(torch.randn(mb_size, z_dim))\n",
    "        X, _ = mnist.train.next_batch(mb_size)\n",
    "        X = Variable(torch.from_numpy(X))\n",
    "\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(z)\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "\n",
    "        D_loss = -(torch.mean(D_real) - torch.mean(D_fake))\n",
    "\n",
    "        D_loss.backward()\n",
    "        D_solver.step()\n",
    "\n",
    "        # Weight clipping\n",
    "        for p in D.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    X, _ = mnist.train.next_batch(mb_size)\n",
    "    X = Variable(torch.from_numpy(X))\n",
    "    z = Variable(torch.randn(mb_size, z_dim))\n",
    "\n",
    "    G_sample = G(z)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    G_loss = -torch.mean(D_fake)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 2000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'\n",
    "              .format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "        samples = G(z).data.numpy()[:16]\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "        plt.savefig('out/{}.png'.format(str(cnt).zfill(3)), bbox_inches='tight')\n",
    "        cnt += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
