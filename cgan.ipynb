{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-70d0e4b9469e>:13: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../../MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../../MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../../MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\ML3614\\lib\\site-packages\\torch\\nn\\functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: 1.385887861251831; G_loss: 2.525507688522339\n",
      "Iter-1000; D_loss: 0.01399793941527605; G_loss: 12.932385444641113\n",
      "Iter-2000; D_loss: 0.00300850928761065; G_loss: 11.041324615478516\n",
      "Iter-3000; D_loss: 0.003748340532183647; G_loss: 7.874301910400391\n",
      "Iter-4000; D_loss: 0.043744370341300964; G_loss: 5.9149065017700195\n",
      "Iter-5000; D_loss: 0.07860356569290161; G_loss: 6.241725444793701\n",
      "Iter-6000; D_loss: 0.09925463795661926; G_loss: 5.378152847290039\n",
      "Iter-7000; D_loss: 0.43708735704421997; G_loss: 6.289834976196289\n",
      "Iter-8000; D_loss: 0.5581288933753967; G_loss: 4.143742561340332\n",
      "Iter-9000; D_loss: 0.5797765851020813; G_loss: 3.6648354530334473\n",
      "Iter-10000; D_loss: 0.6081374883651733; G_loss: 2.818415641784668\n",
      "Iter-11000; D_loss: 0.895980954170227; G_loss: 2.1073153018951416\n",
      "Iter-12000; D_loss: 0.5521987676620483; G_loss: 2.6564388275146484\n",
      "Iter-13000; D_loss: 0.5818083882331848; G_loss: 2.507059335708618\n",
      "Iter-14000; D_loss: 0.9265495538711548; G_loss: 2.6260359287261963\n",
      "Iter-15000; D_loss: 0.9148306250572205; G_loss: 1.8904200792312622\n",
      "Iter-16000; D_loss: 0.6243429183959961; G_loss: 2.3498384952545166\n",
      "Iter-17000; D_loss: 0.6981955766677856; G_loss: 1.9560476541519165\n",
      "Iter-18000; D_loss: 0.8372431397438049; G_loss: 2.0268466472625732\n",
      "Iter-19000; D_loss: 1.122122883796692; G_loss: 1.670868992805481\n",
      "Iter-20000; D_loss: 0.8562940359115601; G_loss: 2.3235623836517334\n",
      "Iter-21000; D_loss: 0.7261242270469666; G_loss: 1.5501902103424072\n",
      "Iter-22000; D_loss: 0.6615305542945862; G_loss: 1.7324341535568237\n",
      "Iter-23000; D_loss: 0.8639216423034668; G_loss: 2.0484976768493652\n",
      "Iter-24000; D_loss: 0.5667083263397217; G_loss: 1.9859498739242554\n",
      "Iter-25000; D_loss: 0.7829203605651855; G_loss: 1.7092056274414062\n",
      "Iter-26000; D_loss: 0.7052344083786011; G_loss: 1.8099826574325562\n",
      "Iter-27000; D_loss: 1.0381181240081787; G_loss: 1.7200459241867065\n",
      "Iter-28000; D_loss: 0.8088786602020264; G_loss: 1.6111780405044556\n",
      "Iter-29000; D_loss: 1.0847328901290894; G_loss: 1.2475199699401855\n",
      "Iter-30000; D_loss: 0.7703495025634766; G_loss: 1.8195921182632446\n",
      "Iter-31000; D_loss: 0.671896755695343; G_loss: 1.8468894958496094\n",
      "Iter-32000; D_loss: 0.8966467380523682; G_loss: 1.6162047386169434\n",
      "Iter-33000; D_loss: 0.8260880708694458; G_loss: 2.1411564350128174\n",
      "Iter-34000; D_loss: 0.7617160081863403; G_loss: 2.0648820400238037\n",
      "Iter-35000; D_loss: 0.7514848113059998; G_loss: 1.7211114168167114\n",
      "Iter-36000; D_loss: 0.7904382944107056; G_loss: 1.860090732574463\n",
      "Iter-37000; D_loss: 0.7797178030014038; G_loss: 2.0000340938568115\n",
      "Iter-38000; D_loss: 0.7475320100784302; G_loss: 2.116211414337158\n",
      "Iter-39000; D_loss: 0.7954574823379517; G_loss: 1.830826997756958\n",
      "Iter-40000; D_loss: 0.5857825875282288; G_loss: 2.1050076484680176\n",
      "Iter-41000; D_loss: 0.6830168962478638; G_loss: 1.8499208688735962\n",
      "Iter-42000; D_loss: 0.9880969524383545; G_loss: 2.015993356704712\n",
      "Iter-43000; D_loss: 0.8853129148483276; G_loss: 1.7983732223510742\n",
      "Iter-44000; D_loss: 0.8502905964851379; G_loss: 1.820359706878662\n",
      "Iter-45000; D_loss: 0.9578925371170044; G_loss: 1.9264167547225952\n",
      "Iter-46000; D_loss: 0.8083950281143188; G_loss: 2.056652307510376\n",
      "Iter-47000; D_loss: 0.8675370216369629; G_loss: 1.8098788261413574\n",
      "Iter-48000; D_loss: 0.8224920034408569; G_loss: 1.8166863918304443\n",
      "Iter-49000; D_loss: 0.7500836849212646; G_loss: 1.7751727104187012\n",
      "Iter-50000; D_loss: 0.9719579815864563; G_loss: 2.025113344192505\n",
      "Iter-51000; D_loss: 0.7406306862831116; G_loss: 1.7815933227539062\n",
      "Iter-52000; D_loss: 0.7596455812454224; G_loss: 1.8229683637619019\n",
      "Iter-53000; D_loss: 0.9606069326400757; G_loss: 1.7255257368087769\n",
      "Iter-54000; D_loss: 0.8532560467720032; G_loss: 1.70331609249115\n",
      "Iter-55000; D_loss: 0.8096900582313538; G_loss: 1.9827476739883423\n",
      "Iter-56000; D_loss: 0.9427066445350647; G_loss: 1.8645431995391846\n",
      "Iter-57000; D_loss: 0.7799035310745239; G_loss: 1.605512022972107\n",
      "Iter-58000; D_loss: 0.6906472444534302; G_loss: 1.9297983646392822\n",
      "Iter-59000; D_loss: 0.8349796533584595; G_loss: 2.119584321975708\n",
      "Iter-60000; D_loss: 0.6506255865097046; G_loss: 2.1567678451538086\n",
      "Iter-61000; D_loss: 0.7852081656455994; G_loss: 2.095851182937622\n",
      "Iter-62000; D_loss: 0.8176404237747192; G_loss: 1.6813442707061768\n",
      "Iter-63000; D_loss: 0.6894683837890625; G_loss: 1.7907261848449707\n",
      "Iter-64000; D_loss: 0.8912301063537598; G_loss: 1.81936514377594\n",
      "Iter-65000; D_loss: 0.7417416572570801; G_loss: 2.095653533935547\n",
      "Iter-66000; D_loss: 0.808584451675415; G_loss: 2.0427119731903076\n",
      "Iter-67000; D_loss: 0.752642035484314; G_loss: 1.8403723239898682\n",
      "Iter-68000; D_loss: 0.6965256929397583; G_loss: 1.6930360794067383\n",
      "Iter-69000; D_loss: 0.9532246589660645; G_loss: 1.7493528127670288\n",
      "Iter-70000; D_loss: 0.7959214448928833; G_loss: 1.8956326246261597\n",
      "Iter-71000; D_loss: 0.8761343955993652; G_loss: 1.8944361209869385\n",
      "Iter-72000; D_loss: 0.5011204481124878; G_loss: 1.8558884859085083\n",
      "Iter-73000; D_loss: 0.8593593239784241; G_loss: 1.9202356338500977\n",
      "Iter-74000; D_loss: 0.7446810007095337; G_loss: 1.8536514043807983\n",
      "Iter-75000; D_loss: 0.7425371408462524; G_loss: 1.8384824991226196\n",
      "Iter-76000; D_loss: 0.6301887631416321; G_loss: 2.012307643890381\n",
      "Iter-77000; D_loss: 0.7022131681442261; G_loss: 2.064887762069702\n",
      "Iter-78000; D_loss: 0.9814136624336243; G_loss: 2.4288365840911865\n",
      "Iter-79000; D_loss: 0.5394721031188965; G_loss: 2.2846157550811768\n",
      "Iter-80000; D_loss: 0.8073820471763611; G_loss: 1.965761423110962\n",
      "Iter-81000; D_loss: 0.619059681892395; G_loss: 1.7864818572998047\n",
      "Iter-82000; D_loss: 0.7083779573440552; G_loss: 1.96267569065094\n",
      "Iter-83000; D_loss: 0.9371945261955261; G_loss: 1.8057719469070435\n",
      "Iter-84000; D_loss: 0.7442334890365601; G_loss: 1.7205023765563965\n",
      "Iter-85000; D_loss: 0.7965644001960754; G_loss: 1.87855064868927\n",
      "Iter-86000; D_loss: 0.7038110494613647; G_loss: 2.1477367877960205\n",
      "Iter-87000; D_loss: 0.7231135368347168; G_loss: 2.1002988815307617\n",
      "Iter-88000; D_loss: 0.7551909685134888; G_loss: 1.9794683456420898\n",
      "Iter-89000; D_loss: 0.8108916282653809; G_loss: 1.8055219650268555\n",
      "Iter-90000; D_loss: 0.9037114381790161; G_loss: 1.8785282373428345\n",
      "Iter-91000; D_loss: 0.9505537748336792; G_loss: 1.900957465171814\n",
      "Iter-92000; D_loss: 0.7810806035995483; G_loss: 1.4415056705474854\n",
      "Iter-93000; D_loss: 0.7596478462219238; G_loss: 1.9216538667678833\n",
      "Iter-94000; D_loss: 0.806222140789032; G_loss: 1.8422966003417969\n",
      "Iter-95000; D_loss: 0.7964667677879333; G_loss: 1.5135159492492676\n",
      "Iter-96000; D_loss: 0.7840255498886108; G_loss: 2.099665880203247\n",
      "Iter-97000; D_loss: 0.5993614196777344; G_loss: 2.09971022605896\n",
      "Iter-98000; D_loss: 0.735121488571167; G_loss: 2.4549474716186523\n",
      "Iter-99000; D_loss: 0.7210017442703247; G_loss: 1.7872604131698608\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "mb_size = 64\n",
    "Z_dim = 100\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)\n",
    "\n",
    "\n",
    "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim + y_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def G(z, c):\n",
    "    inputs = torch.cat([z, c], 1)\n",
    "    h = nn.relu(inputs @ Wzh + bzh.repeat(inputs.size(0), 1))\n",
    "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X\n",
    "\n",
    "\n",
    "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim + y_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X, c):\n",
    "    inputs = torch.cat([X, c], 1)\n",
    "    h = nn.relu(inputs @ Wxh + bxh.repeat(inputs.size(0), 1))\n",
    "    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params\n",
    "\n",
    "\n",
    "\"\"\" ===================== TRAINING ======================== \"\"\"\n",
    "\n",
    "\n",
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            data = p.grad.data\n",
    "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n",
    "\n",
    "ones_label = Variable(torch.ones(mb_size, 1))\n",
    "zeros_label = Variable(torch.zeros(mb_size, 1))\n",
    "\n",
    "\n",
    "for it in range(100000):\n",
    "    # Sample data\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    X, c = mnist.train.next_batch(mb_size)\n",
    "    X = Variable(torch.from_numpy(X))\n",
    "    c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "\n",
    "    # Dicriminator forward-loss-backward-update\n",
    "    G_sample = G(z, c)\n",
    "    D_real = D(X, c)\n",
    "    D_fake = D(G_sample, c)\n",
    "\n",
    "    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    G_sample = G(z, c)\n",
    "    D_fake = D(G_sample, c)\n",
    "\n",
    "    G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "        c = np.zeros(shape=[mb_size, y_dim], dtype='float32')\n",
    "        c[:, np.random.randint(0, 10)] = 1.\n",
    "        c = Variable(torch.from_numpy(c))\n",
    "        samples = G(z, c).data.numpy()[:16]\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "        plt.savefig('out/{}.png'.format(str(cnt).zfill(3)), bbox_inches='tight')\n",
    "        cnt += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
